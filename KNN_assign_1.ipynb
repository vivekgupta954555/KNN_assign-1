{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "522fe2b9-d79d-4e1a-996d-a15241e40e36",
   "metadata": {},
   "source": [
    "# QUES NO 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d687e21-beae-4031-8e5d-578c6a629f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN ALGORITHM\n",
    "\n",
    "The K-Nearest Neighbors (KNN) algorithm is a robust and intuitive machine learning method employed\n",
    "to tackle classification and regression problems. By capitalizing on the concept of similarity,\n",
    "KNN predicts the label or value of a new data point by considering its K closest neighbours in the\n",
    "training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213319d0-7511-4c2e-86e0-5e66389ff885",
   "metadata": {},
   "source": [
    "# QUES NO 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca8d869-0564-4d15-b566-ecb731b68919",
   "metadata": {},
   "outputs": [],
   "source": [
    "The value of k is very crucial in the KNN algorithm to define the number of neighbors in the algorithm.\n",
    "The value of k in the k-nearest neighbors (k-NN) algorithm should be chosen based on the input data. \n",
    "If the input data has more outliers or noise, a higher value of k would be better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da09e928-45a0-45a9-ab0d-9c1996bcd59d",
   "metadata": {},
   "source": [
    "# QUES NO 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee5d9d1-a514-4e79-9e98-8e0782fc8861",
   "metadata": {},
   "source": [
    "The main  differences is the : KNN regression tries to predict the value of  output variable by taking a local average. KNN classification attempts to predict the class to which the output variable belong by computing the local probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa801088-e496-4d64-aaad-8841a0e09f4b",
   "metadata": {},
   "source": [
    "# QUES NO 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b7402d-9d62-41d1-b661-e10c4e522752",
   "metadata": {},
   "outputs": [],
   "source": [
    "To select the value of K that fits your data, we run the KNN algorithm multiple times with different K\n",
    "values. We'll use accuracy as the metric for evaluating K performance. If the value of accuracy changes\n",
    "proportionally to the change in K, then it's a good candidate for our K value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b8484e-8ddb-4d5f-8636-78a74bd7eea3",
   "metadata": {},
   "source": [
    "# QUES NO 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c404099e-f82a-458a-8112-6ebd372b8a6a",
   "metadata": {},
   "source": [
    "While applying k nearest neighbors approach in solving a problem, we can sometimes notice that there is\n",
    "a deterioration in the kNN performance when the number of predictors, p is large. The reason for this can\n",
    "be the high number of dimensions. This problem is known as the curse of dimensionality.\n",
    "\n",
    "It means that the test error tends to increase as the dimensionality of the problem (number of predictors)\n",
    "increases, unless the additional features are truly associated with the response. It is opposite to the \n",
    "thought one might have that as the number of predictors used to fit a model increases, the quality of the\n",
    "fitted model will increase as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1777e6b0-f4c4-4798-8315-2cd96df6f36e",
   "metadata": {},
   "source": [
    "# QUES NO 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec46fa-1ccd-4c35-825c-8f0bdefa2e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN imputation is an effective approach for handling missing data because it considers multiple variables\n",
    "and leverages the concept of nearest neighbors. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5932154-031f-4e60-bfdb-05716149a473",
   "metadata": {},
   "source": [
    "# QUES NO 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f015f37-23db-4bcf-9ebd-ff997fdd08d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN regression tries to predict the value of the output variable by using a local average.\n",
    "KNN classification attempts to predict the class to which the output variable belong by computing\n",
    "the local probability.\n",
    "\n",
    "regression model: codomain of model is a continuous space, e.g\n",
    "these are use to  predict the continous dataset like \n",
    "The weight of a book\n",
    "The height of children\n",
    "The amount of time it takes to sell shoes\n",
    "The amount of rain that falls in a storm\n",
    "\n",
    "classification model: codomain of model is a discrete space, e.g. {0,1}\n",
    "These are used to predict the discreate dataset like\n",
    "\n",
    "The weight of a book\n",
    "The height of children\n",
    "The amount of time it takes to sell shoes\n",
    "The amount of rain that falls in a storm\n",
    "The square footage of a house\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba210577-3a95-4596-9140-3822fa81bce7",
   "metadata": {},
   "source": [
    "# QUES NO 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a3e5b8-7e27-4cb7-8d0a-8085032ceb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Advantages of KNN\n",
    "\n",
    "1. No Training Period: KNN is called Lazy Learner (Instance based learning). It does not learn anything\n",
    "in the training period. It does not derive any discriminative function from the training data. In other\n",
    "words, there is no training period for it. It stores the training dataset and learns from it only at the\n",
    "time of making real time predictions. This makes the KNN algorithm much faster than other algorithms that \n",
    "require training e.g. SVM, Linear Regression etc.\n",
    "\n",
    "2. Since the KNN algorithm requires no training before making predictions, new data can be added seamlessly\n",
    "which will not impact the accuracy of the algorithm.\n",
    "\n",
    "3. KNN is very easy to implement. There are only two parameters required to implement KNN i.e. the value \n",
    "of K and the distance function (e.g. Euclidean or Manhattan etc.)\n",
    "\n",
    "Disadvantages of KNN\n",
    "\n",
    "1. Does not work well with large dataset: In large datasets, the cost of calculating the distance between\n",
    "the new point and each existing points is huge which degrades the performance of the algorithm.\n",
    "\n",
    "2. Does not work well with high dimensions: The KNN algorithm doesn't work well with high dimensional data\n",
    "because with large number of dimensions, it becomes difficult for the algorithm to calculate the distance in\n",
    "each dimension.\n",
    "\n",
    "3. Need feature scaling: We need to do feature scaling (standardization and normalization) before applying\n",
    "KNN algorithm to any dataset. If we don't do so, KNN may generate wrong predictions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eec85b-8572-451b-9694-205ed684375e",
   "metadata": {},
   "source": [
    "# QUES NO 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a7461b-412c-4a04-bbd0-13e24b75bcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Both Euclidean distance and Manhattan distance are measures of distance between two points in\n",
    "a multidimensional space. However, they differ in how they calculate the distance between the points.\n",
    "Euclidean distance is the straight-line distance between two points, as measured by Pythagoras' theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0dc8c8-70d4-41c7-8bfa-a991a026dadb",
   "metadata": {},
   "source": [
    "# QUES NO 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da98fde-ba3c-4369-aa18-014f76c5c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "We need to do feature scaling (standardization and normalization) before applying KNN algorithm to any\n",
    "dataset. If we don't do so, KNN may generate wrong predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4af30d-a948-4923-961d-662c9d189d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
